import cv2
import redis
import json
import time
import base64
# import psycopg2
# from detic.predictor import DeticPredictor
import numpy as np
from io import BytesIO
from PIL import Image
# from transformers import CLIPProcessor, CLIPModel
# from PIL import Image

# Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)
r = redis.Redis(host='127.0.0.1', port=6379, db=0)
# r = redis.Redis(host='localhost', port=6379, db=0)
pub_sub = r.pubsub()
pub_sub.subscribe('vlm_server')

def run():
    # Listen for messages
    # i = 0
    for message in pub_sub.listen():
        if message['type'] == 'message':
            try:
                msg = message['data'].decode()
                # JSON ë¬¸ìì—´ì„ íŒŒì‹±
                payload = json.loads(msg)

                # ê° í•„ë“œ ì¶”ì¶œ
                frame_id = payload.get("frame_id")
                detections = payload.get("detections", [])
                img_base64 = payload.get("image")
                processing_time = payload.get("processing_time")

                image_data = base64.b64decode(img_base64)
                pil_img = Image.open(BytesIO(image_data)).convert("RGB")
                rgb_img = np.array(pil_img)
                bgr_img = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2BGR)

                # í•„ìš”í•œ ì²˜ë¦¬ ë¡œì§ ì‚½ì… (ì˜ˆ: ë¡œê¹…, ì´ë¯¸ì§€ ë””ì½”ë”© ë“±)
                print(f"[frame_id={frame_id}] {len(detections)} detections, time: {processing_time:.3f}s")

                cv2.imshow("vlm receiver", bgr_img)

                # 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
                if cv2.waitKey(10) & 0xFF == ord('q'):
                    break                
            except json.JSONDecodeError as e:
                print(f"[ERROR] Invalid JSON: {e}")
            except Exception as e:
                print(f"[ERROR] Unexpected error: {e}")

if __name__ == '__main__':
    run()

# # # PostgreSQL ì—°ê²° ì„¤ì •
# # conn = psycopg2.connect(
# #     dbname="your_db_name",
# #     user="your_username",
# #     password="your_password",
# #     host="localhost",
# #     port="5432"
# # )
# # cursor = conn.cursor()

# # # PostgreSQL í…Œì´ë¸” ìƒì„± (ìµœì´ˆ 1íšŒ ì‹¤í–‰)
# # cursor.execute("""
# #     CREATE TABLE IF NOT EXISTS detections (
# #         id SERIAL PRIMARY KEY,
# #         frame_id INTEGER,
# #         rt_class VARCHAR(50),
# #         rt_confidence FLOAT,
# #         rt_bbox JSONB,
# #         rt_time TIMESTAMP,
# #         event_info TEXT,
# #         frame_path TEXT,
# #         vlm_description TEXT,
# #         processing_time FLOAT
# #     );
# # """)
# # conn.commit()

# # # Detic ëª¨ë¸ ì´ˆê¸°í™”
# # detic_predictor = DeticPredictor(
# #     model_type="Detic_LCOCOI21k_CLIP_SwinB_896b32_4x_ft4x_max-size",
# #     confidence_threshold=0.5
# # )

# # VLM (CLIP) ëª¨ë¸ ì´ˆê¸°í™”
# clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
# clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# # Redis Stream ì´ë¦„
# STREAM_NAME = "video_frames_stream"

# # í”„ë ˆì„ ì²˜ë¦¬ ê°„ê²© (ì´ˆ)
# FRAME_PROCESSING_INTERVAL = 1.0

# # ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
# results_list = []

# # ë§ˆì§€ë§‰ìœ¼ë¡œ ì²˜ë¦¬í•œ ë©”ì‹œì§€ ID ì´ˆê¸°í™”
# last_id = "0-0"

# try:
#     # while True:
#         # Redis Streamì—ì„œ ë©”ì‹œì§€ ì½ê¸° (ì¼ì • ê°„ê²©ìœ¼ë¡œ í´ë§)

#         # messages = redis_client.xread({STREAM_NAME: last_id}, block=1000, count=1)
#         # if isinstance(detection_str, bytes):
#     for message in pub_sub.listen():
#         if message['type'] != 'message':
#             continue

#         try:
#             # Decode JSON
#             payload = json.loads(message['data'].decode('utf-8'))

#             # Extract detection info
#             detection = payload.get("detection", {})
#             frame_id = detection.get("frame_id")
#             cls = detection.get("rt_class")
#             conf = detection.get("rt_confidence")
#             bbox = detection.get("rt_bbox")
#             timestamp = detection.get("rt_time")

#             print(f"ğŸ“¦ Detection - Frame: {frame_id}, Class: {cls}, Score: {conf}, BBox: {bbox}, Time: {timestamp}")

#             # Decode image
#             img_base64 = payload.get("image")
#             img_bytes = base64.b64decode(img_base64)
#             img_array = np.frombuffer(img_bytes, dtype=np.uint8)
#             img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)

#             if img is not None:
#                 # Optional: draw bbox
#                 if bbox:
#                     x1, y1, x2, y2 = bbox
#                     cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
#                     cv2.putText(img, f"{cls} {conf:.2f}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

#                 cv2.imshow("Received Image", img)
#                 if cv2.waitKey(1) & 0xFF == ord('q'):
#                     break
#             else:
#                 print("âš ï¸ Failed to decode image")

#         except Exception as e:
#             print("âŒ Error processing message:", e)

#                 # Deticìœ¼ë¡œ ê°ì²´ ê²€ì¶œ
#                 predictions = detic_predictor.predict(frame)

#                 # ê²€ì¶œ ê²°ê³¼ ì²˜ë¦¬
#                 detections = []
#                 for pred in predictions:
#                     bbox = pred["bbox"]  # [x_min, y_min, x_max, y_max]
#                     class_name = pred["class_name"]
#                     confidence = pred["confidence"]

#                     # ROI ì¶”ì¶œ
#                     x_min, y_min, x_max, y_max = map(int, bbox)
#                     roi = frame[y_min:y_max, x_min:x_max]
#                     if roi.size == 0:  # ROIê°€ ë¹„ì–´ìˆìœ¼ë©´ ìŠ¤í‚µ
#                         continue

#                     # ROIë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
#                     roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
#                     roi_pil = Image.fromarray(roi_rgb)

#                     # VLM (CLIP)ìœ¼ë¡œ ROI ì„¤ëª… ìƒì„±
#                     inputs = clip_processor(
#                         text=["A person walking", "A car on the road", "A dog running", "An empty street"],  # VLM í”„ë¡¬í”„íŠ¸
#                         images=roi_pil,
#                         return_tensors="pt",
#                         padding=True
#                     )
#                     outputs = clip_model(**inputs)
#                     logits_per_image = outputs.logits_per_image
#                     probs = logits_per_image.softmax(dim=1).detach().numpy()
#                     max_prob_idx = np.argmax(probs[0])
#                     vlm_description = inputs["text"][max_prob_idx]

#                     # ê²€ì¶œ ê²°ê³¼ ì €ì¥
#                     detection = {
#                         "rt_class": class_name,
#                         "rt_confidence": float(confidence),
#                         "rt_bbox": [x_min, y_min, x_max, y_max],
#                         "rt_time": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
#                         "event_info": event_info,
#                         "vlm_description": vlm_description
#                     }
#                     detections.append(detection)

#                     # ë°”ìš´ë”© ë°•ìŠ¤ì™€ ë ˆì´ë¸” ê·¸ë¦¬ê¸°
#                     cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
#                     label = f"{class_name} {confidence:.2f} ({vlm_description})"
#                     cv2.putText(frame, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

#                 # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
#                 frame_result = {
#                     "frame_id": len(results_list),
#                     "detections": detections,
#                     "event_info": event_info,
#                     "frame_path": frame_path,
#                     "processing_time": time.time() - start_time
#                 }
#                 results_list.append(frame_result)

#                 # PostgreSQLì— ì €ì¥
#                 for detection in detections:
#                     cursor.execute("""
#                         INSERT INTO detections (frame_id, rt_class, rt_confidence, rt_bbox, rt_time, event_info, frame_path, vlm_description, processing_time)
#                         VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s);
#                     """, (
#                         frame_result["frame_id"],
#                         detection["rt_class"],
#                         detection["rt_confidence"],
#                         json.dumps(detection["rt_bbox"]),
#                         detection["rt_time"],
#                         detection["event_info"],
#                         frame_path,
#                         detection["vlm_description"],
#                         frame_result["processing_time"]
#                     ))
#                 conn.commit()

#                 # ê²°ê³¼ í™”ë©´ í‘œì‹œ
#                     cv2.imshow("Detic + VLM Real-time Detection", frame)

#         # 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
#         if cv2.waitKey(1) & 0xFF == ord('q'):
#             break

#         # ì²˜ë¦¬ ê°„ê²© ì¡°ì •
#         elapsed_time = time.time() - start_time
#         if elapsed_time < FRAME_PROCESSING_INTERVAL:
#             time.sleep(FRAME_PROCESSING_INTERVAL - elapsed_time)

# except Exception as e:
#     print(f"Error: {e}")

# finally:
#     # ë¦¬ì†ŒìŠ¤ í•´ì œ
#     cv2.destroyAllWindows()
#     cursor.close()
#     conn.close()

#     # ê²°ê³¼ JSON íŒŒì¼ë¡œ ì €ì¥ (ì¶”ê°€ í™•ì¸ìš©)
#     with open("detection_results.json", "w") as f:
#         json.dump(results_list, f, indent=4)